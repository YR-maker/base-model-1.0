"""
æ¨¡å‹æ¨ç†è„šæœ¬ - æ”¯æŒå¤šGPUå¹¶è¡Œæ¨ç† & åŠ¨æ€è·ç¦»çº¦æŸä¸å½¢æ€å­¦ç¼åˆ
ä¿®æ”¹ç‚¹:
1. å¢åŠ å¤šè¿›ç¨‹ (Multiprocessing) æ”¯æŒï¼Œå®ç°å¤šå¡å¹¶è¡Œæ¨ç†ã€‚
2. æ•°æ®é›†è‡ªåŠ¨åˆ‡åˆ†ã€‚
3. æŒ‡æ ‡ç»“æœè·¨è¿›ç¨‹æ±‡æ€»ã€‚
"""
import logging
import warnings
from pathlib import Path
import re
import math
import time

import torch
import torch.nn.functional as F
import torch.multiprocessing as mp
import hydra
import numpy as np
from tqdm import tqdm
from monai.inferers import SlidingWindowInfererAdapt

# å¼•å…¥å›¾åƒå¤„ç†åº“
from skimage import morphology, measure
from scipy import ndimage

# ä¿æŒåŸæœ‰å¼•ç”¨
from utils.dataset import generate_transforms
from utils.io import determine_reader_writer
from utils.evaluation import Evaluator, calculate_mean_metrics

warnings.filterwarnings("ignore")
# é…ç½® logging æ ¼å¼ï¼ŒåŒ…å«è¿›ç¨‹åä»¥ä¾¿åŒºåˆ†
logging.basicConfig(format='[%(processName)s] %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)


# ==============================================================================
#  æ ¸å¿ƒé€»è¾‘ï¼šè·ç¦»çº¦æŸä¸ç¼åˆ (ä¿æŒä¸å˜)
# ==============================================================================

def distance_based_postprocessing(pred_data, closing_radius=3, center_threshold=50.0):
    """
    Args:
        pred_data: äºŒå€¼åŒ–é¢„æµ‹ç»“æœ (D, H, W)
        closing_radius: é—­è¿ç®—åŠå¾„ï¼Œç”¨äºç¼åˆæ–­è£‚ã€‚
        center_threshold: è·ç¦»é˜ˆå€¼ã€‚
    """
    # 1. ã€ç¼åˆæ–­è£‚ã€‘ Morphological Closing
    if closing_radius > 0:
        struct = morphology.ball(closing_radius)
        bridged_data = ndimage.binary_closing(pred_data, structure=struct)
    else:
        bridged_data = pred_data.copy()

    # 2. ã€è¿é€šåŸŸåˆ†æã€‘
    lbl, num = measure.label(bridged_data, connectivity=2, return_num=True)

    if num == 0:
        return bridged_data

    # 3. ã€æ„å»ºè·ç¦»åœºã€‘
    d, h, w = bridged_data.shape
    cz, cy, cx = d // 2, h // 2, w // 2 # å›¾åƒä¸­å¿ƒåæ ‡

    zz, yy, xx = np.ogrid[:d, :h, :w]
    dist_map = np.sqrt((zz - cz)**2 + (yy - cy)**2 + (xx - cx)**2)

    # 4. ã€è·ç¦»ç­›é€‰ã€‘
    final_mask = np.zeros_like(bridged_data)

    for i in range(1, num + 1):
        component_mask = (lbl == i)
        component_dists = dist_map[component_mask]
        min_dist_to_center = component_dists.min()

        if min_dist_to_center <= center_threshold:
            final_mask[component_mask] = 1

    # 5. ã€å…œåº•ç­–ç•¥ã€‘
    if np.sum(final_mask) == 0:
        regions = measure.regionprops(lbl)
        regions.sort(key=lambda x: x.area, reverse=True)
        if len(regions) > 0:
            final_mask[lbl == regions[0].label] = 1

    return final_mask > 0.5


# ==============================================================================
#  è¾…åŠ©å‡½æ•°
# ==============================================================================

def load_model(cfg, device):
    ckpt_path = Path(cfg.ckpt_path)
    # logger.info(f"Loading models from {ckpt_path} to {device}")

    if not ckpt_path.exists():
        raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {ckpt_path}")

    try:
        # æ˜¾å¼æŒ‡å®š map_location åˆ°å½“å‰è¿›ç¨‹çš„ GPU
        ckpt = torch.load(ckpt_path, map_location=device, weights_only=False)
    except Exception as e:
        logger.error(f"åŠ è½½æ¨¡å‹æ–‡ä»¶å¤±è´¥: {e}")
        raise

    model = hydra.utils.instantiate(cfg.model)
    state_dict_to_load = None

    if 'state_dict' in ckpt:
        state_dict = ckpt['state_dict']
        new_state_dict = {}
        for key, value in state_dict.items():
            key = key.replace('model.', '').replace('models.', '').replace('net.', '').replace('module.', '')
            new_state_dict[key] = value
        state_dict_to_load = new_state_dict
    elif isinstance(ckpt, dict) and any(key.startswith(('encoder', 'decoder', 'backbone')) for key in ckpt.keys()):
        state_dict_to_load = ckpt
    else:
        state_dict_to_load = ckpt

    if state_dict_to_load is not None:
        try:
            model.load_state_dict(state_dict_to_load, strict=True)
        except RuntimeError as e:
            model.load_state_dict(state_dict_to_load, strict=False)
    else:
        raise ValueError("æƒé‡æ–‡ä»¶æ ¼å¼ä¸æ”¯æŒ")

    return model


def get_paths_nested(cfg):
    """è·å–æ‰€æœ‰æ–‡ä»¶è·¯å¾„ï¼Œä¸åœ¨æ­¤å¤„åˆ‡åˆ†ï¼Œåœ¨ä¸»å‡½æ•°åˆ‡åˆ†"""
    root_dir = Path(hydra.utils.to_absolute_path(cfg.image_path))
    if not root_dir.exists():
        raise FileNotFoundError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {root_dir}")

    image_paths = []
    mask_paths = []
    case_dirs = sorted([d for d in root_dir.iterdir() if d.is_dir()])

    # ä»…ä¸»è¿›ç¨‹æ‰“å°ä¸€æ¬¡
    if mp.current_process().name == 'MainProcess':
        logger.info(f"åœ¨ {root_dir} ä¸­æ‰¾åˆ° {len(case_dirs)} ä¸ªå­æ–‡ä»¶å¤¹")

    for case_dir in case_dirs:
        case_id = case_dir.name
        img_name = f"{case_id}{cfg.image_file_ending}"
        img_p = case_dir / img_name

        if img_p.exists():
            image_paths.append(img_p)
            if cfg.get('mask_suffix') and cfg.get('mask_path'):
                label_name = f"{case_id}{cfg.mask_suffix}"
                label_p = case_dir / label_name
                if label_p.exists():
                    mask_paths.append(label_p)
        else:
            pass

    if not image_paths:
        raise FileNotFoundError(f"æœªåœ¨ {root_dir} çš„å­æ–‡ä»¶å¤¹ä¸­æ‰¾åˆ°ä»»ä½•ç¬¦åˆè§„åˆ™çš„å›¾åƒã€‚")

    if mask_paths and len(mask_paths) != len(image_paths):
        if cfg.get('strict_matching', True):
            raise ValueError("æ ‡ç­¾æ•°é‡ä¸åŒ¹é…")
        else:
            mask_paths = None

    if not mask_paths:
        return image_paths, None
    return image_paths, mask_paths


def resample(image, factor=None, target_shape=None):
    if factor == 1: return image
    if target_shape:
        _, _, new_d, new_h, new_w = target_shape
    else:
        _, _, d, h, w = image.shape
        new_d, new_h, new_w = int(round(d / factor)), int(round(h / factor)), int(round(w / factor))
    return F.interpolate(image, size=(new_d, new_h, new_w), mode="trilinear", align_corners=False)


# ==============================================================================
#  Worker è¿›ç¨‹é€»è¾‘
# ==============================================================================

def inference_worker(rank, gpu_id, image_paths, mask_paths, cfg, result_queue):
    """
    Args:
        rank: è¿›ç¨‹ç¼–å· (0, 1, 2...)
        gpu_id: å®é™…ä½¿ç”¨çš„ CUDA ID (å¦‚ 0, 1...)
        image_paths: å½“å‰è¿›ç¨‹åˆ†é…åˆ°çš„å›¾åƒè·¯å¾„åˆ—è¡¨
        mask_paths: å½“å‰è¿›ç¨‹åˆ†é…åˆ°çš„æ©è†œè·¯å¾„åˆ—è¡¨
        cfg: é…ç½®å¯¹è±¡
        result_queue: ç”¨äºå›ä¼ ç»“æœçš„é˜Ÿåˆ—
    """
    try:
        device = torch.device(f"cuda:{gpu_id}")
        torch.cuda.set_device(device)  # é‡è¦ï¼šè®¾ç½®å½“å‰è¿›ç¨‹çš„é»˜è®¤ GPU

        # åŠ è½½æ¨¡å‹ (æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹åŠ è½½)
        model = load_model(cfg, device)
        model.to(device)
        model.eval()

        transforms = generate_transforms(cfg.transforms_config)

        # å‡†å¤‡ IO
        if len(image_paths) > 0:
            first_name = image_paths[0].name
            if 'nii.gz' in first_name:
                rw_suffix = 'nii.gz'
                save_ext = '.nii.gz'
            else:
                rw_suffix = image_paths[0].suffix
                save_ext = image_paths[0].suffix
            image_reader_writer = determine_reader_writer(rw_suffix)()
            save_writer = determine_reader_writer(rw_suffix)()

        # å‡†å¤‡è¾“å‡ºç›®å½•
        save_predictions = False
        output_folder = None
        if cfg.output_folder and str(cfg.output_folder).lower() != "none" and str(cfg.output_folder).strip() != "":
            save_predictions = True
            output_folder = Path(cfg.output_folder)
            output_folder.mkdir(parents=True, exist_ok=True)

        inferer = SlidingWindowInfererAdapt(
            roi_size=cfg.patch_size,
            sw_batch_size=cfg.batch_size,
            overlap=cfg.overlap,
            mode=cfg.mode,
            sigma_scale=cfg.sigma_scale,
            padding_mode=cfg.padding_mode
        )

        local_metrics = {}

        # è¿›åº¦æ¡ (positionæ§åˆ¶å¤šè¡Œæ˜¾ç¤º)
        pbar = tqdm(enumerate(image_paths), total=len(image_paths),
                    desc=f"GPU {gpu_id}", position=rank, leave=True)

        with torch.no_grad():
            for idx, image_path in pbar:
                try:
                    img_data = image_reader_writer.read_images(image_path)[0].astype(np.float32)
                except Exception as e:
                    logger.error(f"GPU {gpu_id} è¯»å–å¤±è´¥ {image_path}: {e}")
                    continue

                # --- TTA & Inference ---
                preds = []
                for scale in cfg.tta.scales:
                    image_tensor = transforms(img_data)
                    if isinstance(image_tensor, np.ndarray):
                        image_tensor = torch.from_numpy(image_tensor)
                    if image_tensor.ndim == 3:
                        image_tensor = image_tensor.unsqueeze(0)
                    image = image_tensor.unsqueeze(0).to(device)

                    if cfg.tta.invert and image.mean() > cfg.tta.invert_mean_thresh:
                        image = 1 - image

                    original_shape = image.shape
                    image = resample(image, factor=scale)
                    logits = inferer(image, model)
                    logits = resample(logits, target_shape=original_shape)
                    preds.append(logits.cpu().squeeze())

                if len(preds) > 1:
                    stacked_preds = torch.stack(preds)
                    if cfg.merging.max:
                        pred = stacked_preds.max(dim=0)[0].sigmoid()
                    else:
                        pred = stacked_preds.mean(dim=0).sigmoid()
                else:
                    pred = preds[0].sigmoid()

                pred_thresh = (pred > cfg.merging.threshold).numpy()

                # ====================================================
                # åº”ç”¨åŠ¨æ€è·ç¦»çº¦æŸä¸ç¼åˆåå¤„ç†
                # ====================================================
                if cfg.post.apply:
                    pred_bool = pred_thresh.astype(bool)
                    d, h, w = pred_bool.shape

                    # ç”¨æˆ·æ–°å…¬å¼: median(x, y, z) * 0.5
                    sorted_dims = sorted([d, h, w])
                    median_dim = sorted_dims[1]
                    dynamic_thresh = (median_dim+10) * 0.4

                    processed_mask = distance_based_postprocessing(
                        pred_bool,
                        closing_radius=cfg.post.closing_radius,
                        center_threshold=dynamic_thresh
                    )
                    pred_thresh = processed_mask.astype(np.uint8)
                else:
                    pred_thresh = pred_thresh.astype(np.uint8)
                # ====================================================

                if save_predictions:
                    clean_name = re.sub(r'\.img\.nii(\.gz)?$', '', image_path.name)
                    save_name = f"{clean_name}{cfg.file_app}{save_ext}"
                    save_path = output_folder / save_name
                    save_writer.write_seg(pred_thresh, save_path)

                # è®¡ç®—æŒ‡æ ‡
                mask = None
                if mask_paths:
                    try:
                        # æ³¨æ„ï¼šimage_pathsæ˜¯åˆ‡åˆ†è¿‡çš„ï¼Œidxæ˜¯ç›¸å¯¹ç´¢å¼•
                        mask_data = image_reader_writer.read_images(mask_paths[idx])[0]
                        mask = torch.tensor(mask_data).bool().to(device)
                    except Exception:
                        pass

                if mask is not None:
                    post_processed_tensor = torch.from_numpy(pred_thresh).float().to(device)
                    metrics = Evaluator().estimate_metrics(post_processed_tensor, mask, threshold=0.5)

                    # --- å…¼å®¹ float å’Œ Tensor ç±»å‹ ---
                    metrics_cpu = {}
                    for k, v in metrics.items():
                        if hasattr(v, 'item'):
                            metrics_cpu[k] = v.item()
                        else:
                            metrics_cpu[k] = v

                    fname = image_path.name
                    local_metrics[fname] = metrics_cpu

                    # === ã€æ–°å¢ã€‘æ‰“å°æ¯ä¸ªæ ·æœ¬çš„ Dice å’Œ clDice ===
                    # å°è¯•è·å– dice å’Œ cldiceï¼Œå¦‚æœé”®åä¸åŒè¯·æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ (é€šå¸¸æ˜¯ 'dice', 'cldice')
                    d_score = metrics_cpu.get('dice', metrics_cpu.get('Dice', -1))
                    c_score = metrics_cpu.get('cldice', metrics_cpu.get('clDice', -1))

                    # ä½¿ç”¨ logger æ‰“å°ï¼Œä¸ºäº†ä¸ç ´åè¿›åº¦æ¡æ˜¾ç¤ºï¼Œå¯ä»¥ä½¿ç”¨ short print
                    # æ³¨æ„ï¼šåœ¨å¤šè¿›ç¨‹ä¸‹ console è¾“å‡ºå¯èƒ½ä¼šç©¿æ’ï¼Œå»ºè®®æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶æˆ–æ¥å—è¿™ç§ç©¿æ’
                    logger.info(f"GPU-{gpu_id} | {fname} | Dice: {d_score:.4f} | clDice: {c_score:.4f}")

        # å°†æœ¬è¿›ç¨‹çš„ç»“æœæ”¾å…¥é˜Ÿåˆ—
        result_queue.put(local_metrics)

    except Exception as e:
        logger.error(f"Worker {rank} (GPU {gpu_id}) failed: {e}")
        result_queue.put({})  # å‘é€ç©ºç»“æœé˜²æ­¢ä¸»è¿›ç¨‹æ­»é”
        raise e

# ==============================================================================
#  ä¸»æµç¨‹
# ==============================================================================

@hydra.main(config_path="../configs", config_name="post_infer", version_base="1.3.2")
def main(cfg):
    # 1. ç¡®å®šä½¿ç”¨çš„ GPU åˆ—è¡¨
    # ä¼˜å…ˆä» cfg.devices è¯»å– (å¦‚ [0,1,2,3])
    # å¦‚æœæ²¡æœ‰ï¼Œå°è¯•è§£æ cfg.device (å¦‚ "cuda:0")
    # å¦‚æœéƒ½æ²¡æœ‰ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨ GPU
    target_devices = []

    if 'devices' in cfg and cfg.devices is not None:
        target_devices = list(cfg.devices)
    elif str(cfg.device).lower() != 'cpu':
        if "cuda" in str(cfg.device):
            # å¤„ç† "cuda:0" è¿™ç§æ ¼å¼
            try:
                device_id = int(str(cfg.device).split(":")[-1])
                target_devices = [device_id]
            except:
                pass

    if not target_devices:
        if torch.cuda.is_available():
            target_devices = list(range(torch.cuda.device_count()))
        else:
            logger.error("æ— å¯ç”¨ GPUï¼Œæœ¬è„šæœ¬ä»…æ”¯æŒ CUDA æ¨ç†ã€‚")
            return

    logger.info(f"ğŸš€ å¯åŠ¨å¤š GPU æ¨ç†ï¼Œä½¿ç”¨è®¾å¤‡ IDs: {target_devices}")

    # 2. è·å–æ‰€æœ‰æ•°æ®è·¯å¾„
    all_image_paths, all_mask_paths = get_paths_nested(cfg)
    total_images = len(all_image_paths)
    num_gpus = len(target_devices)

    # 3. å¯åŠ¨å¤šè¿›ç¨‹
    mp.set_start_method('spawn', force=True) # CUDA å¿…é¡»ä½¿ç”¨ spawn
    result_queue = mp.Queue()
    processes = []

    for rank, gpu_id in enumerate(target_devices):
        # æ•°æ®åˆ‡åˆ†ï¼šç®€å•åˆ‡ç‰‡æ³• paths[0::4], paths[1::4]...
        subset_images = all_image_paths[rank::num_gpus]
        subset_masks = all_mask_paths[rank::num_gpus] if all_mask_paths else []

        if len(subset_images) == 0:
            continue

        p = mp.Process(
            target=inference_worker,
            args=(rank, gpu_id, subset_images, subset_masks, cfg, result_queue)
        )
        p.start()
        processes.append(p)

    # 4. æ”¶é›†ç»“æœ
    all_metrics = {}
    finished_workers = 0

    # å¾ªç¯æ¥æ”¶ç»“æœï¼Œç›´åˆ°æ‰€æœ‰ worker å‘é€å®Œæ¯•
    while finished_workers < len(processes):
        # é˜»å¡è·å–ï¼Œè®¾ç½®è¶…æ—¶é˜²æ­¢æ­»é”
        try:
            worker_result = result_queue.get() # é˜»å¡ç­‰å¾…
            all_metrics.update(worker_result)
            finished_workers += 1
        except Exception as e:
            # ç®€å•çš„é”™è¯¯å¤„ç†
            pass

    for p in processes:
        p.join()

    # 5. æœ€ç»ˆç»Ÿè®¡
    if all_metrics:
        logger.info("\n" + "=" * 60)
        logger.info("æ±‡æ€»æ‰€æœ‰ GPU ç»“æœ:")
        # å°†å­—å…¸çš„å€¼è½¬ä¸ºåˆ—è¡¨ä»¥é€‚é… calculate_mean_metrics
        # æ³¨æ„: calculate_mean_metrics æœŸæœ›è¾“å…¥æ˜¯ list of dicts
        # è¿™é‡Œçš„ all_metrics æ˜¯ {fname: {dice: 0.9, ...}}
        metrics_list = list(all_metrics.values())

        # calculate_mean_metrics éœ€è¦é€‚é…çº¯ float è¾“å…¥ (å› ä¸ºæˆ‘ä»¬åœ¨ worker é‡Œè½¬æˆäº† float)
        # å¦‚æœåŸå‡½æ•°åªæ”¯æŒ Tensorï¼Œå¯èƒ½éœ€è¦ç®€å•ä¿®æ”¹ã€‚é€šå¸¸å®ƒæ˜¯æ”¯æŒ numpy/dict çš„ã€‚
        # è¿™é‡Œå‡è®¾ calculate_mean_metrics èƒ½å¤Ÿå¤„ç†ã€‚

        try:
            mean_metrics = calculate_mean_metrics(metrics_list, round_to=cfg.round_to)

            logger.info("=" * 60)
            logger.info(f"FINAL AVERAGE METRICS ({len(all_metrics)} cases):")
            logger.info("=" * 60)
            for key in sorted(mean_metrics.keys()):
                val = mean_metrics[key]
                val = val.item() if hasattr(val, 'item') else val
                logger.info(f"Mean {key:<25}: {val:.4f}")
            logger.info("=" * 60)
        except Exception as e:
            logger.error(f"è®¡ç®—å¹³å‡æŒ‡æ ‡æ—¶å‡ºé”™ (å¯èƒ½æ˜¯æ•°æ®æ ¼å¼é—®é¢˜): {e}")
            # ç®€å•æ‰“å°ä¸€ä¸‹ Dice å‡å€¼å…œåº•
            dices = [m.get('dice', 0) for m in metrics_list]
            logger.info(f"Simple Mean Dice: {np.mean(dices):.4f}")

    elif all_mask_paths:
        logger.warning("æœªè®¡ç®—å‡ºä»»ä½•æŒ‡æ ‡ã€‚")

    logger.info("Inference finished.")

if __name__ == "__main__":
    main()