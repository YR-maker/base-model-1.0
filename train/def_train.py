import logging, sys, warnings, os, hydra, torch, numpy as np
from pathlib import Path
from omegaconf import OmegaConf
from torch.utils.data import RandomSampler, Dataset
from lightning.pytorch import seed_everything, Trainer
from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint
from lightning.pytorch.loggers import WandbLogger, CSVLogger
from utils.dataset import UnionDataset
from utils.evaluation import Evaluator

# --- ç¯å¢ƒä¸å…¼å®¹æ€§è®¾ç½® ---
sys.path.append(str(Path(__file__).resolve().parent.parent))

# ã€å±è”½è­¦å‘Šã€‘
warnings.filterwarnings("ignore")
warnings.filterwarnings("ignore", message=".*pkg_resources.*")
os.environ["PYTHONWARNINGS"] = "ignore"

# ã€å±è”½å†—ä½™æ§åˆ¶å°è¾“å‡ºã€‘
logging.getLogger("lightning.pytorch").setLevel(logging.ERROR)
logging.getLogger("torch.distributed").setLevel(logging.ERROR)
logging.getLogger("monai").setLevel(logging.ERROR)

try:
    import monai.transforms.transform

    monai.transforms.transform.MAX_SEED = 0xFFFFFFFF
except ImportError:
    pass

logger = logging.getLogger(__name__)


# --- è¾…åŠ©ç±»ä¸å‡½æ•° ---

# ã€æ–°å¢ã€‘è‡ªå®šä¹‰ CSVLoggerï¼Œç”¨äºç¦æ­¢ä¿å­˜ hparams.yaml
class CleanCSVLogger(CSVLogger):
    """
    ä¿®æ”¹ç‰ˆçš„ CSVLoggerï¼š
    1. ä¸ä¿å­˜ hparams.yaml
    2. ä»…ä¿å­˜ metrics.csv
    """

    def log_hyperparams(self, params):
        # è¦†ç›–çˆ¶ç±»æ–¹æ³•ï¼Œä»€ä¹ˆéƒ½ä¸åšï¼Œä»è€Œç¦æ­¢ä¿å­˜ hparams.yaml
        pass


class InMemoryDataset(Dataset):
    """å†…å­˜æ•°æ®é›†ï¼Œæå‡å°æ ·æœ¬è®­ç»ƒé€Ÿåº¦"""

    def __init__(self, data, transform): self.data, self.transform = data, transform

    def __len__(self): return len(self.data)

    def __getitem__(self, idx):
        d = self.transform(self.data[idx])
        return d['Image'], d['Mask'] > 0


def safe_load_weights(model, ckpt_path, rank=0):
    """æ™ºèƒ½åŠ è½½æƒé‡"""
    if not ckpt_path: return
    if rank == 0: logger.info(f"ğŸ”„ æ­£åœ¨åŠ è½½æƒé‡: {ckpt_path}")

    try:
        ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=True)
    except:
        ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)

    state = ckpt.get('state_dict', ckpt.get('model_state_dict', ckpt))
    state = {k.replace('model.', '').replace('models.', ''): v for k, v in state.items()}

    try:
        model.load_state_dict(state, strict=False)
    except RuntimeError:
        if rank == 0: logger.warning("âš ï¸ æ£€æµ‹åˆ°å±‚ç»“æ„ä¸åŒ¹é…ï¼Œæ­£åœ¨æ™ºèƒ½è¿‡æ»¤...")
        curr = model.state_dict()
        state = {k: v for k, v in state.items() if k in curr and v.shape == curr[k].shape}
        model.load_state_dict(state, strict=False)
    if rank == 0: logger.info("âœ… æƒé‡åŠ è½½æˆåŠŸã€‚")


def get_loader(cfg, phase, rank=0, batch_size=1):
    raw_ds = UnionDataset(cfg.data, phase, finetune=True)
    if phase == "test":
        if rank == 0: logger.info(f"æµ‹è¯•é›†: {len(raw_ds)}")
        return hydra.utils.instantiate(cfg.dataloader)(dataset=raw_ds, batch_size=batch_size)

    if not raw_ds.datasets: return None
    info = raw_ds.datasets[0]
    paths, reader, trans = info["paths"], info["reader"], info["transforms"]

    limit = min(cfg.num_shots, len(paths)) if phase == "train" else len(paths)
    if rank == 0: logger.info(f"ğŸš€ æ­£åœ¨å°† {phase} é›† ({limit} æ ·æœ¬) åŠ è½½åˆ°å†…å­˜...")

    data = []
    for p in paths[:limit]:
        img = reader.read_images(str(next(p.glob('*img*'))))[0].astype(np.float32)
        msk = reader.read_images(str(next(p.glob('*label*'))))[0].astype(bool)
        data.append({'Image': img, 'Mask': msk})

    mem_ds = InMemoryDataset(data, trans)

    if phase == "train":
        sampler = RandomSampler(mem_ds, replacement=True, num_samples=int(1e5) // len(cfg.devices))
        return hydra.utils.instantiate(cfg.dataloader)(dataset=mem_ds, sampler=sampler)
    else:
        return hydra.utils.instantiate(cfg.dataloader)(dataset=mem_ds, batch_size=1)


# --- æ ¸å¿ƒå›è°ƒ ---
class LogCallback(LearningRateMonitor):
    def on_validation_end(self, trainer, pl_module):
        if trainer.global_rank != 0: return
        m = trainer.callback_metrics
        d_name, epoch = pl_module.dataset_name, trainer.current_epoch
        score, loss = m.get(f"{d_name}_val_dice"), m.get(f"{d_name}_val_loss")
        best = trainer.checkpoint_callback.best_model_score if trainer.checkpoint_callback else None

        logger.info(f"{'=' * 30} Epoch {epoch} {'=' * 30}")
        if score: logger.info(f"âœ… {d_name} Dice: {score:.4f}")
        if loss:  logger.info(f"ğŸ“‰ éªŒè¯ Loss: {loss:.4f}")

        if best and score:
            diff = float(score) - float(best)
            icon = "ğŸš€ æ–°çºªå½•!" if diff > 0 else ("âš–ï¸  æŒå¹³" if diff == 0 else f"ğŸ”™ å·®è·: {diff:.4f}")
            logger.info(f"â­ å†å²æœ€ä½³: {best:.4f} | {icon}")
        logger.info("=" * 67)


# --- ä¸»ç¨‹åº ---
@hydra.main(config_path="../configs", config_name="train/mutil_train", version_base="1.3.2")
def main(cfg):
    seed_everything(cfg.seed, True)
    torch.set_float32_matmul_precision("medium")
    rank = int(os.environ.get("RANK", 0))

    d_name = list(cfg.data.keys())[0]
    # æ„å»ºå®éªŒåç§°
    run_name = f'{cfg.loss_name}_{cfg.num_shots}shot_{os.path.basename(os.path.normpath(cfg.data[d_name].path))}'

    # ã€ä¿®æ”¹ç‚¹ 1ã€‘æ„å»ºå®Œæ•´çš„å®éªŒç›®å½•è·¯å¾„ï¼š.../doc/{æ•°æ®é›†}/{å®éªŒå}
    base_doc_path = f"/home/yangrui/Project/Base-model/local_results/doc/{cfg.data_name}"
    experiment_dir = os.path.join(base_doc_path, run_name)

    if rank == 0:
        os.makedirs(experiment_dir, exist_ok=True)

    steps = cfg.trainer.lightning_trainer.max_steps // len(cfg.devices)
    val_int = max(1, steps // 25)
    if rank == 0: logger.info(f"ğŸ§® åŠ¨æ€ç­–ç•¥: æ€»æ­¥æ•°={steps}, éªŒè¯é—´éš”={val_int}, GPUæ•°é‡={len(cfg.devices)}")

    # ã€ä¿®æ”¹ç‚¹ 2ã€‘é…ç½® Logger
    loggers = [
        # WandB: save_dir è®¾ä¸º experiment_dirï¼Œè¿™æ · wandb æ–‡ä»¶å¤¹å°±ä¼šç”Ÿæˆåœ¨å®éªŒç›®å½•ä¸‹
        WandbLogger(
            save_dir=experiment_dir,
            name=run_name,
            config=OmegaConf.to_container(cfg),
            offline=True,
            mode="offline"
        ),
        # CSV: ä½¿ç”¨è‡ªå®šä¹‰ CleanCSVLogger
        # save_dir è®¾ä¸º experiment_dirï¼ŒåŒæ—¶æŠŠ name å’Œ version è®¾ä¸ºç©º
        # è¿™æ · metrics.csv å°±ä¼šç›´æ¥ç”Ÿæˆåœ¨ experiment_dir ä¸‹ï¼Œä¸”æ²¡æœ‰ hparams.yaml
        CleanCSVLogger(
            save_dir=experiment_dir,
            name="",
            version=""
        )
    ]

    # ModelCheckpoint
    ckpt_cb = ModelCheckpoint(
        dirpath=f"{cfg.chkpt_folder}/{cfg.data_name}/{os.path.basename(os.path.normpath(cfg.data[d_name].path))}/{run_name}",
        monitor="val_DiceMetric",
        mode="max",
        save_top_k=1,
        save_last=True,
        filename="{step}-dice:{val_DiceMetric:.2f}-" + f"{len(cfg.devices)}GPU",
        auto_insert_metric_name=False
    )
    ckpt_cb.CHECKPOINT_EQUALS_CHAR = ":"
    ckpt_cb.CHECKPOINT_NAME_LAST = run_name + "_last"

    train_dl = get_loader(cfg, "train", rank)
    val_dl = get_loader(cfg, "val", rank)
    test_dl = get_loader(cfg, "test", rank)

    model = hydra.utils.instantiate(cfg.model)
    safe_load_weights(model, cfg.path_to_chkpt, rank)

    pl_module = hydra.utils.instantiate(cfg.trainer.lightning_module)(model=model, evaluator=Evaluator(),
                                                                      dataset_name=d_name)

    trainer = hydra.utils.instantiate(cfg.trainer.lightning_trainer,
                                      logger=loggers, callbacks=[LearningRateMonitor(), ckpt_cb, LogCallback()],
                                      max_steps=steps, val_check_interval=val_int, devices=cfg.devices,
                                      accelerator="gpu", strategy="ddp", sync_batchnorm=True,
                                      use_distributed_sampler=False,
                                      enable_model_summary=False
                                      )()

    if cfg.num_shots == 0:
        if rank == 0: logger.info("ğŸš€ å¼€å§‹é›¶æ ·æœ¬è¯„ä¼° (Zero-Shot)")
        trainer.test(pl_module, test_dl)
    else:
        if rank == 0: logger.info("ğŸš€ å¼€å§‹å¾®è°ƒæµç¨‹ (åˆå§‹éªŒè¯ -> è®­ç»ƒ -> æµ‹è¯•)")
        trainer.validate(pl_module, val_dl)
        trainer.fit(pl_module, train_dl, val_dl)
        trainer.test(pl_module, test_dl, ckpt_path="best")

    if rank == 0:
        res = trainer.callback_metrics
        logger.info(f"\nğŸ† æœ€ç»ˆæµ‹è¯• Dice: {res.get('test_DiceMetric', 0):.4f} | æ—¥å¿—è·¯å¾„: {experiment_dir}")


if __name__ == "__main__":
    sys.stdout = open(sys.stdout.fileno(), mode="w", buffering=1)
    sys.stderr = open(sys.stderr.fileno(), mode="w", buffering=1)
    os.environ["WANDB_SILENT"] = "true"
    os.environ["WANDB_MODE"] = "offline"
    main()