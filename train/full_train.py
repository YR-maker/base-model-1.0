import logging, sys, warnings, os, hydra, torch
from pathlib import Path
from omegaconf import OmegaConf

from lightning.pytorch import seed_everything
from lightning.pytorch.callbacks import LearningRateMonitor, ModelCheckpoint
from lightning.pytorch.loggers import WandbLogger, CSVLogger

# å¼•å…¥æ”¯æŒ repeats çš„ Dataset
from utils.full_train_dataset import UnionDataset
from utils.evaluation import Evaluator

# --- ç¯å¢ƒè®¾ç½® ---
sys.path.append(str(Path(__file__).resolve().parent.parent))

# å±è”½è­¦å‘Šä¸å†—ä½™æ—¥å¿—
warnings.filterwarnings("ignore")
os.environ["PYTHONWARNINGS"] = "ignore"
logging.getLogger("lightning.pytorch").setLevel(logging.ERROR)
logging.getLogger("torch.distributed").setLevel(logging.ERROR)
logging.getLogger("monai").setLevel(logging.ERROR)

try:
    import monai.transforms.transform

    monai.transforms.transform.MAX_SEED = 0xFFFFFFFF
except ImportError:
    pass

logger = logging.getLogger(__name__)


# --- è‡ªå®šä¹‰ç»„ä»¶ ---

class CleanCSVLogger(CSVLogger):
    """ä¸ä¿å­˜ hparams.yaml çš„æ¸…çˆ½ç‰ˆ CSVLogger"""

    def log_hyperparams(self, params):
        pass


class LogCallback(LearningRateMonitor):
    """ä¸­æ–‡æ—¥å¿—ç›‘æ§å›è°ƒ"""

    def on_validation_end(self, trainer, pl_module):
        if trainer.global_rank != 0: return
        m = trainer.callback_metrics
        d_name, epoch = pl_module.dataset_name, trainer.current_epoch

        score = m.get(f"{d_name}_val_dice") or m.get("val_DiceMetric")
        loss = m.get(f"{d_name}_val_loss") or m.get("val_loss")

        # è·å–å†å²æœ€ä½³ (æ³¨æ„ï¼šè¿™é‡Œè·å–çš„æ˜¯ Checkpoint callback ä¸­è®°å½•çš„å€¼)
        # å¦‚æœ Checkpoint callback å°šæœªæ›´æ–°ï¼Œè¿™é‡Œå°±æ˜¯ä¸Šä¸€è½®çš„æœ€ä½³
        best = trainer.checkpoint_callback.best_model_score if trainer.checkpoint_callback else None

        logger.info(f"{'=' * 30} Epoch {epoch} {'=' * 30}")
        if score: logger.info(f"âœ… éªŒè¯ Dice: {score:.4f}")
        if loss:  logger.info(f"ğŸ“‰ éªŒè¯ Loss: {loss:.4f}")

        if best and score:
            diff = float(score) - float(best)
            # ã€ä¿®æ”¹ç‚¹ã€‘ä¼˜åŒ–æ˜¾ç¤ºæ–‡æ¡ˆï¼Œæ˜¾ç¤ºå…·ä½“å·®å€¼
            if diff > 1e-6:
                icon = f"ğŸš€ æ–°çºªå½•! (+{diff:.4f})"  # æ˜¾ç¤ºæå‡å¹…åº¦
            elif diff > -1e-6:
                icon = "âš–ï¸  æŒå¹³"
            else:
                icon = f"ğŸ”™ å·®è·: {diff:.4f}"  # æ˜¾ç¤ºè½åå¹…åº¦(è´Ÿæ•°)

            logger.info(f"â­ å†å²æœ€ä½³: {best:.4f} | {icon}")
        logger.info("=" * 67)


def safe_load_weights(model, ckpt_path, rank=0):
    """æ™ºèƒ½æƒé‡åŠ è½½"""
    if not ckpt_path: return
    if rank == 0: logger.info(f"ğŸ”„ æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæƒé‡: {ckpt_path}")

    try:
        ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=True)
    except:
        ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)

    state = ckpt.get('state_dict', ckpt.get('model_state_dict', ckpt))
    state = {k.replace('model.', '').replace('models.', '').replace('net.', ''): v for k, v in state.items()}

    try:
        model.load_state_dict(state, strict=False)
    except RuntimeError:
        if rank == 0: logger.warning("âš ï¸ æ£€æµ‹åˆ°å±‚ç»“æ„ä¸åŒ¹é…ï¼Œæ­£åœ¨æ™ºèƒ½è¿‡æ»¤ä¸å…¼å®¹çš„å±‚...")
        curr = model.state_dict()
        filtered_state = {k: v for k, v in state.items() if k in curr and v.shape == curr[k].shape}
        model.load_state_dict(filtered_state, strict=False)

    if rank == 0: logger.info("âœ… æƒé‡åŠ è½½å®Œæˆ")


# --- ä¸»ç¨‹åº ---
@hydra.main(config_path="../configs", config_name="train/full_train", version_base="1.3.2")
def main(cfg):
    seed_everything(cfg.seed, True)
    torch.set_float32_matmul_precision("medium")
    rank = int(os.environ.get("RANK", 0))

    d_name = list(cfg.data.keys())[0]
    run_name = f'FullTrain_{cfg.loss_name}_{os.path.basename(os.path.normpath(cfg.data[d_name].path))}'

    base_doc_path = f"../local_results/doc/{cfg.data_name}"
    experiment_dir = os.path.join(base_doc_path, run_name)
    if rank == 0: os.makedirs(experiment_dir, exist_ok=True)

    loggers = [
        WandbLogger(save_dir=experiment_dir, name=run_name, config=OmegaConf.to_container(cfg), offline=True,
                    mode="offline"),
        CleanCSVLogger(save_dir=experiment_dir, name="", version="")
    ]

    ckpt_cb = ModelCheckpoint(
        dirpath=f"{cfg.chkpt_folder}/{cfg.data_name}/{os.path.basename(os.path.normpath(cfg.data[d_name].path))}/{run_name}",
        monitor="val_DiceMetric",
        mode="max",
        save_top_k=1,
        save_last=True,
        filename="epoch:{epoch:d}-dice:{val_DiceMetric:.2f}",
        auto_insert_metric_name=False
    )
    ckpt_cb.CHECKPOINT_EQUALS_CHAR = "="
    ckpt_cb.CHECKPOINT_NAME_LAST = f"{run_name}_last"

    # --- æ•°æ®åŠ è½½é…ç½® ---
    # ã€æ ¸å¿ƒä¿®æ”¹ã€‘ä»é…ç½®æ–‡ä»¶è¯»å– repeatsï¼Œé»˜è®¤ä¸º 1
    # è¿™æ ·ä½ åªéœ€è¦åœ¨ yaml é‡Œæ”¹ repeats: 8 å³å¯
    repeats = cfg.get("repeats", 1)

    train_dataset = UnionDataset(cfg.data, "train", finetune=True, repeats=repeats)
    val_dataset = UnionDataset(cfg.data, "val", finetune=True, repeats=1)
    test_dataset = UnionDataset(cfg.data, "test", finetune=True, repeats=1)

    if rank == 0:
        logger.info(f"ğŸ“Š [æ•°æ®é›†æ¦‚è§ˆ] å…¨é‡è®­ç»ƒæ¨¡å¼")
        logger.info(f"   - åŸå§‹æ ·æœ¬æ•°: {len(train_dataset) // repeats}")
        logger.info(f"   - é‡‡æ ·å€ç‡ (repeats): {repeats} (æ¯ä¸ªEpochå¯¹æ¯å¼ å›¾è£ {repeats} æ¬¡)")
        logger.info(f"   - Train (Virtual): {len(train_dataset)} æ ·æœ¬")
        logger.info(f"   - Val: {len(val_dataset)} æ ·æœ¬")

    train_loader = hydra.utils.instantiate(cfg.dataloader)(
        dataset=train_dataset,
        batch_size=cfg.batch_size,
        shuffle=True,
        pin_memory=True,
        drop_last=True
    )
    val_loader = hydra.utils.instantiate(cfg.dataloader)(dataset=val_dataset, batch_size=1, shuffle=False)
    test_loader = hydra.utils.instantiate(cfg.dataloader)(dataset=test_dataset, batch_size=1, shuffle=False)

    model = hydra.utils.instantiate(cfg.model)
    safe_load_weights(model, cfg.path_to_chkpt, rank)

    pl_module = hydra.utils.instantiate(cfg.trainer.lightning_module)(
        model=model,
        evaluator=Evaluator(),
        dataset_name=d_name
    )

    trainer = hydra.utils.instantiate(cfg.trainer.lightning_trainer,
                                      logger=loggers,
                                      callbacks=[LearningRateMonitor(), ckpt_cb, LogCallback()],
                                      devices=cfg.devices,
                                      accelerator="gpu",
                                      strategy="ddp",
                                      sync_batchnorm=True,
                                      enable_model_summary=False,
                                      )()

    if rank == 0:
        logger.info(f"ğŸš€ å¼€å§‹å…¨é‡è®­ç»ƒ")
        logger.info(f"   - æ€»è½®æ•°: {trainer.max_epochs}")
        logger.info(f"   - è¯„ä¼°é¢‘ç‡: æ¯ {trainer.check_val_every_n_epoch} Epochs")

    trainer.fit(pl_module, train_loader, val_loader)

    if rank == 0: logger.info("âœ… è®­ç»ƒå®Œæˆï¼Œå¼€å§‹æœ€ç»ˆæµ‹è¯•...")
    trainer.test(pl_module, test_loader, ckpt_path="best")

    if rank == 0:
        res = trainer.callback_metrics
        logger.info(f"\nğŸ† æœ€ç»ˆæµ‹è¯• Dice: {res.get('test_DiceMetric', 0):.4f}")


if __name__ == "__main__":
    sys.stdout = open(sys.stdout.fileno(), mode="w", buffering=1)
    sys.stderr = open(sys.stderr.fileno(), mode="w", buffering=1)
    os.environ["WANDB_SILENT"] = "true"
    os.environ["WANDB_MODE"] = "offline"
    main()